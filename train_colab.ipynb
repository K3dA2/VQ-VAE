{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOusACWYpBeBZ59gIkwZBbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K3dA2/VQ-VAE/blob/main/train_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ZpCzGDFpNO",
        "outputId": "85ea678a-e097-4a94-8a7b-cc22b3d90856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4dq6F4sFp-P",
        "outputId": "d82814d5-d82e-411b-a16b-7f5a0050771f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download scribbless/another-anime-face-dataset\n",
        "! unzip another-anime-face-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ozkC0dAFspu",
        "outputId": "714ceea3-04e9-4560-c788-e9518e68fe7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/scribbless/another-anime-face-dataset\n",
            "License(s): GPL-2.0\n",
            "another-anime-face-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  another-anime-face-dataset.zip\n",
            "replace animefaces256cleaner/10004131_result.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/K3dA2/VQ-VAE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DpAfBToFvEd",
        "outputId": "10f12dba-fd64-42f4-e106-d641ab7a1fef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'VQ-VAE' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/VQ-VAE/')"
      ],
      "metadata": {
        "id": "SB0Z1CfxGdkY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "import os\n",
        "import torch.nn.utils as utils\n",
        "from model import VQVAE\n",
        "from utils import get_data_loader,count_parameters\n",
        "import uuid\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4RIinyzGlF2",
        "outputId": "ced5632f-40bf-4eac-bc3b-341eda74b694"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out shape: torch.Size([2, 3, 128, 128])\n",
            "loss shape: 0.5168724656105042\n",
            "torch.Size([1, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, fname))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Return the image and a dummy label (e.g., 0)\n",
        "        return image, 0\n",
        "\n",
        "def get_data_loader(path, batch_size, num_samples=None, shuffle=True):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.7002, 0.6099, 0.6036), (0.2195, 0.2234, 0.2097))\n",
        "    ])\n",
        "\n",
        "    full_dataset = CustomDataset(root_dir=path, transform=transform)\n",
        "\n",
        "    if num_samples is None or num_samples > len(full_dataset):\n",
        "        num_samples = len(full_dataset)\n",
        "    print(\"data length:\", len(full_dataset))\n",
        "\n",
        "    if shuffle:\n",
        "        indices = random.sample(range(len(full_dataset)), num_samples)\n",
        "    else:\n",
        "        indices = list(range(num_samples))\n",
        "\n",
        "    subset_dataset = Subset(full_dataset, indices)\n",
        "\n",
        "    data_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "0-ZKoOdIKNh4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/animefaces256cleaner'\n",
        "batch_size = 32\n",
        "data_loader = get_data_loader(path, batch_size, num_samples=None, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjAtVvVWKPNE",
        "outputId": "b116a0fc-0b2a-4d50-82ad-36fbe8eec7b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data length: 92219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, device, data_loader,\\\n",
        "                   max_grad_norm=1.0, epoch_start = 0,\\\n",
        "                    save_img = False, show_img = True):\n",
        "    model.train()\n",
        "    for epoch in range(epoch_start,n_epochs):\n",
        "        loss_train = 0.0\n",
        "\n",
        "        progress_bar = tqdm(data_loader, desc=f'Epoch {epoch}', unit=' batch')\n",
        "        for imgs, _ in progress_bar:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "\n",
        "            outputs,c_loss = model(imgs)\n",
        "            loss = loss_fn(outputs, imgs) + c_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            #utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Save model checkpoint with the current epoch in the filename\n",
        "        model_filename = f'waifu-vqvae.pth'\n",
        "        model_path = os.path.join('/content/drive/MyDrive/VQ-VAE Weights/', model_filename)\n",
        "\n",
        "        with open(\"waifu-vqvae_epoch-loss.txt\", \"a\") as file:\n",
        "            file.write(f\"{loss_train / len(data_loader)}\\n\")\n",
        "\n",
        "        print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(data_loader)))\n",
        "        if epoch % 20 == 0:\n",
        "            if show_img:\n",
        "                pred_images = model.inference(1, 14, 14)\n",
        "                plt.imshow(np.transpose(pred_images[-1].cpu().numpy(), (1, 2, 0)))\n",
        "                plt.show()\n",
        "            if save_img:\n",
        "                pred_images = model.inference(1, 14, 14)\n",
        "                pred_images = np.transpose(pred_images[-1].cpu().numpy(), (1, 2, 0))\n",
        "                random_filename = str(uuid.uuid4()) + '.png'\n",
        "\n",
        "                # Specify the directory where you want to save the image\n",
        "                save_directory = path\n",
        "\n",
        "                # Create the full path including the directory and filename\n",
        "                full_path = os.path.join(save_directory, random_filename)\n",
        "                # Save the image with the random filename\n",
        "                plt.savefig(full_path, bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "            torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, model_path)"
      ],
      "metadata": {
        "id": "jyFw3qzqGoaL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/animefaces256cleaner'\n",
        "#model_path = '/content/drive/MyDrive/VQ-VAE Weights/waifu-vqvae.pth'\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "model = VQVAE()  # Assuming Unet is correctly imported and defined\n",
        "model.to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "#loss_fn = nn.L1Loss().to(device)\n",
        "loss_fn = nn.MSELoss().to(device)\n",
        "print(count_parameters(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diqiriP8GrFb",
        "outputId": "07c32449-1238-4262-854f-76a3be0d7b9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cpu\n",
            "31209996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally load model weights if needed\n",
        "#checkpoint = torch.load(model_path)\n",
        "#model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#epoch = checkpoint['epoch']"
      ],
      "metadata": {
        "id": "6SHFeqIcHbmc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\n",
        "    n_epochs=1000,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    device=device,\n",
        "    data_loader=data_loader,\n",
        "    epoch_start= 0,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KP57RxsHeVM",
        "outputId": "a4551a3e-7274-41e1-a250-fff32b00b194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 0:   0%|          | 0/2882 [00:00<?, ? batch/s]"
          ]
        }
      ]
    }
  ]
}